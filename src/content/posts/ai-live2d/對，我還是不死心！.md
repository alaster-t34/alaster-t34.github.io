---
title: 對，我還是不死心！
published: 2025-01-14
description: ''
image: './wuhei.jpg'
tags: [AI, Live2D]
category: 'ive2d'
draft: false 
lang: ''
---

這一篇是續著上一篇的《FaiREE-AIイラストか》而寫的，因爲發現上一篇那個幾乎沒啥用，並不能解決我的問題（笑）。衆所周知，我會畫立繪，但是！我太懶了，而且因爲時間問題（我的時間永遠是斷斷續續的），就打算讓AI製作live2d模型。<br>

- 首先不得不承認的是：直接通过代码生成 Live2D 模型是相对复杂的<br>
因为 Live2D 模型的创建涉及到图像处理、骨骼动画和物理引擎等多个方面，而这些技术都是相对复杂的。因此，直接通过代码生成 Live2D 模型并不现实。
- 但是：理论上是可以通过编程生成或自动化 Live2D 模型的部分步骤<br>
這些部分步驟，比如图像处理、骨骼动画和物理引擎，理论上是可以自动化完成的。比如，图像处理部分，可以利用计算机视觉技术，对人物的照片进行分析，提取出人物的轮廓、皮肤、眼睛、嘴巴等特征，并将这些特征转化为 Live2D 模型的贴图。骨骼动画部分，可以利用机器学习算法，对人物的动作进行分析，并生成 Live2D 模型的动画。物理引擎部分，可以利用物理模拟技术，模拟人物的运动，并生成 Live2D 模型的物理效果。
- 因此：理论上是可以自动化生成 Live2D 模型的<br>

### 關於 自动化图像切割与建模
尽管 Live2D 的建模和动画主要依赖于手动操作和设计，但可以使用一些代码工具（如 Python 脚本）来辅助自动化某些部分（應該），比如：在图像的切割和图层划分上。<br>
步驟的話：<br>
图像处理：使用 Python 的 OpenCV 库对图像进行处理，提取出人物的轮廓、皮肤、眼睛、嘴巴等特征。（或者PIL库）<br>
导出 Live2D 数据：理论上，可以通过代码将这些分割后的图层和骨骼设定转换为 Live2D 模型所需的格式（如 .moc3、.model3.json 等）。（然而，这部分需要深刻了解 Live2D 的文件格式和动画规则，是一个非常复杂的过程。）<br>

### 關於 自动化骨骼动画生成
Live2D 的动画生成主要依赖于手动操作，但可以使用一些代码工具（如 Python 脚本）来辅助自动化某些部分（應該），比如：在动作的分析和动画生成上。<br>
步驟的話：<br>
动作分析：使用 Python 的 OpenCV 库对视频进行处理，提取出人物的动作特征。（或者用其他的动作识别库）<br>
导出 Live2D 数据：理论上，可以通过代码将动作特征转换为 Live2D 模型的动画文件（如 .motion3.json 等）。（然而，这部分需要深刻了解 Live2D 的文件格式和动画规则）<br>

### 關於 自动化物理引擎生成
Live2D 的物理引擎生成主要依赖于手动操作，但可以使用一些代码工具（如 Python 脚本）来辅助自动化某些部分（~~應該~~），比如：在人物的运动模拟上。<br>
步驟的話：<br>
运动模拟：使用 Python 的 PyBullet 库进行物理模拟，模拟人物的运动。（或者用其他的物理引擎库~~?~~）<br>
导出 Live2D 数据：理论上，可以通过代码将物理模拟结果转换为 Live2D 模型的物理文件（如 .physics3.json 等）。（然而，这部分需要深刻了解 Live2D 的文件格式和物理规则）<br>

### ~~結論~~
~~Live2D 模型的自动化生成，理论上是可以实现的，但還屬於起步階段。<br>~~
~~并且不是一個大一統的程序可以解決的（就目前而言因爲要寫這莫一個程序是十分複雜的，畢竟是生成系統，文件而非一張動畫）~~

## 難道這就結束了嗎？終歸是徒勞嗎？不，一定是遺漏了什麽······

因爲是要構建一個live2d模型文件夾，所以，根據下載的那麽多文件來看，首先是拆分出來的圖片，然後再來是動畫文件，最後是物理文件。那麽對這三個都進行自動化生成，那麽就需要有一個自動化工具，這個工具可以將圖片切割、動畫生成、物理模擬，然後合併成一個live2d模型文件夾。

那麽，這個工具應該要有什麽功能呢？

- 圖片切割：將圖片切割成可以被Live2D模型使用的格式，例如.moc3、.model3.json等。
- 動畫生成：將動作轉換成Live2D模型的動畫文件，例如.motion3.json等。
- 物理模擬：將物理模擬結果轉換成Live2D模型的物理文件，例如.physics3.json等。
- 合併文件：將圖片、動畫、物理文件合併成一個Live2D模型文件夾。

所以<br>
* 1.圖像分割技術。通過使用深度神經網絡（如捲積神經網絡，CNN）。有如下三種辦法。
 * α.深度學習模型（如 U-Net、Mask R-CNN）<br>
利用模型進行語義分割，即自主識別圖像的不同區域（如頭髮、眼睛、嘴巴等）。這個可以將關鍵部位提取至單獨圖層。
 * β.工具和框架<br>
  * DeepLabV3：Google提供的一個深度學習模型，用於圖像分割；
  * RunwayML：一個圖像分割工具，可以將圖像分割成不同類別的區域。
  Stable Diffusion 或 MidJourney（生成图像辅助工具）：~~虽然这些工具主要用于生成图像，但也有潜力帮助生成分层图像，或通过风格转换将图像转化为适合 Live2D 的风格。~~
 * ~~γ.懶人的現成AI工具~~<br>
~~AI Studio：[^提供Live2D模型的生成，可以直接上傳照片，生成Live2D模型文件夾。]~~:（你在想什麽?真有這莫好的工具？那我早用了！還寫個damn）
* 自動拆分工具~~（？還有這玩意？）~~

